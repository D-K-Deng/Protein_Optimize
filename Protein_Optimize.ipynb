{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOmHlmdSG9TRysRFa/w6x25",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/D-K-Deng/Protein_Optimize/blob/main/Protein_Optimize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GtnRJMItNCF"
      },
      "outputs": [],
      "source": [
        "#@title Main Process\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "!pip install -q biopython\n",
        "from google.colab import files\n",
        "import os\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "import pandas as pd\n",
        "from sys import version_info\n",
        "\n",
        "\n",
        "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
        "seq_test=\"MCCNRGKNVSIENLHQGFTHIFESTFESTEGVAEYVSHPSHVEYANLFLANLEKVLVIDYKPTTVRV\" #@param {type:\"string\"}\n",
        "hr = [\"R\", \"D\", \"H\", \"N\", \"E\", \"Q\", \"K\"] #@param hr {type:\"string\", description:\"hydrophobic residues that need to be changed, write in list format\"}\n",
        "ranges=[(11,25),(29,37),(39,56)]#@param hr {type:\"string\", description:\"helices locations, write in list format, this is an example of location 11-25 29-37 39-56\"}\n",
        "results=[]\n",
        "TL=[]\n",
        "TH=[]\n",
        "PC=[]\n",
        "HM=[]\n",
        "NHM=[]\n",
        "\n",
        "#Sequence Generation\n",
        "\n",
        "def get_actual_ranges(ranges, length):\n",
        "    \"\"\"Compute the actual replacement ranges considering boundaries and overlaps.\"\"\"\n",
        "    actual_ranges = []\n",
        "    for start, end in ranges:\n",
        "        actual_start = max(1, start - 5)\n",
        "        actual_end = min(length, end + 5)\n",
        "        actual_ranges.append((actual_start, actual_end))\n",
        "\n",
        "    # Merge overlapping ranges\n",
        "    merged_ranges = []\n",
        "    sorted_ranges = sorted(actual_ranges, key=lambda x: x[0])\n",
        "    for r in sorted_ranges:\n",
        "        if not merged_ranges or r[0] > merged_ranges[-1][1]:\n",
        "            merged_ranges.append(r)\n",
        "        else:\n",
        "            merged_ranges[-1] = (merged_ranges[-1][0], max(merged_ranges[-1][1], r[1]))\n",
        "\n",
        "    return merged_ranges\n",
        "\n",
        "def replace_in_range(sequence, start, end, replace_chars):\n",
        "    \"\"\"Find all possible replacements in the given range.\"\"\"\n",
        "    # Find positions of replaceable characters in the given range\n",
        "    replace_positions = [i for i in range(start, end + 1) if sequence[i-1] in replace_chars]\n",
        "\n",
        "    results = []\n",
        "    if not replace_positions:\n",
        "        return [sequence]\n",
        "\n",
        "    for pos in replace_positions:\n",
        "        # Replace one character\n",
        "        new_seq = sequence[:pos-1] + 'K' + sequence[pos:]\n",
        "        results.append(new_seq)\n",
        "\n",
        "        # Replace two characters\n",
        "        for sec_pos in replace_positions:\n",
        "            if sec_pos > pos:\n",
        "                new_seq_2 = new_seq[:sec_pos-1] + 'K' + new_seq[sec_pos:]\n",
        "                results.append(new_seq_2)\n",
        "\n",
        "    return results\n",
        "\n",
        "def generate_replacements(sequence, ranges, replace_chars):\n",
        "    \"\"\"Generate all possible replacements for the given sequence.\"\"\"\n",
        "    actual_ranges = get_actual_ranges(ranges, len(sequence))\n",
        "    results = [sequence]\n",
        "\n",
        "    for start, end in actual_ranges:\n",
        "        new_results = []\n",
        "        for seq in results:\n",
        "            new_results.extend(replace_in_range(seq, start, end, replace_chars))\n",
        "        results = new_results\n",
        "\n",
        "    return results\n",
        "\n",
        "ans=generate_replacements(seq_test, ranges, hr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Recursion_Seq(seq_str):\n",
        "  import os\n",
        "\n",
        "  def add_hash(x,y):\n",
        "    return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
        "  query_sequence = seq_str\n",
        "  jobname = 'test'\n",
        "  # number of models to use\n",
        "  num_relax = 1\n",
        "  template_mode = \"none\"\n",
        "\n",
        "\n",
        "  use_amber = num_relax > 0\n",
        "\n",
        "  # remove whitespaces\n",
        "  query_sequence = \"\".join(query_sequence.split())\n",
        "  basejobname = \"\".join(jobname.split())\n",
        "  basejobname = re.sub(r'\\W+', '', basejobname)\n",
        "  jobname = add_hash(basejobname, query_sequence)\n",
        "\n",
        "  # check if directory with jobname exists\n",
        "  def check(folder):\n",
        "    if os.path.exists(folder):\n",
        "      return False\n",
        "    else:\n",
        "      return True\n",
        "  if not check(jobname):\n",
        "    n = 0\n",
        "    while not check(f\"{jobname}_{n}\"): n += 1\n",
        "    jobname = f\"{jobname}_{n}\"\n",
        "\n",
        "  # make directory to save results\n",
        "  os.makedirs(jobname, exist_ok=True)\n",
        "\n",
        "  # save queries\n",
        "  queries_path = os.path.join(jobname, f\"{jobname}.csv\")\n",
        "  with open(queries_path, \"w\") as text_file:\n",
        "    text_file.write(f\"id,sequence\\n{jobname},{query_sequence}\")\n",
        "\n",
        "  if template_mode == \"pdb100\":\n",
        "    use_templates = True\n",
        "    custom_template_path = None\n",
        "  elif template_mode == \"custom\":\n",
        "    custom_template_path = os.path.join(jobname,f\"template\")\n",
        "    os.makedirs(custom_template_path, exist_ok=True)\n",
        "    uploaded = files.upload()\n",
        "    use_templates = True\n",
        "    for fn in uploaded.keys():\n",
        "      os.rename(fn,os.path.join(custom_template_path,fn))\n",
        "  else:\n",
        "    custom_template_path = None\n",
        "    use_templates = False\n",
        "\n",
        "  print(\"jobname\",jobname)\n",
        "  print(\"sequence\",query_sequence)\n",
        "  print(\"length\",len(query_sequence.replace(\":\",\"\")))\n",
        "  #@title Install dependencies\n",
        "  import os\n",
        "  USE_AMBER = use_amber\n",
        "  USE_TEMPLATES = use_templates\n",
        "  PYTHON_VERSION = python_version\n",
        "\n",
        "  if not os.path.isfile(\"COLABFOLD_READY\"):\n",
        "    print(\"installing colabfold...\")\n",
        "    os.system(\"pip install -q --no-warn-conflicts 'colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold'\")\n",
        "    os.system(\"pip install --upgrade dm-haiku\")\n",
        "    os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\")\n",
        "    os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\")\n",
        "    # patch for jax > 0.3.25\n",
        "    os.system(\"sed -i 's/weights = jax.nn.softmax(logits)/logits=jnp.clip(logits,-1e8,1e8);weights=jax.nn.softmax(logits)/g' alphafold/model/modules.py\")\n",
        "    os.system(\"touch COLABFOLD_READY\")\n",
        "\n",
        "  if USE_AMBER or USE_TEMPLATES:\n",
        "    if not os.path.isfile(\"CONDA_READY\"):\n",
        "      print(\"installing conda...\")\n",
        "      os.system(\"wget -qnc https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh\")\n",
        "      os.system(\"bash Mambaforge-Linux-x86_64.sh -bfp /usr/local\")\n",
        "      os.system(\"mamba config --set auto_update_conda false\")\n",
        "      os.system(\"touch CONDA_READY\")\n",
        "\n",
        "  if USE_TEMPLATES and not os.path.isfile(\"HH_READY\") and USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
        "    print(\"installing hhsuite and amber...\")\n",
        "    os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 openmm=7.7.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
        "    os.system(\"touch HH_READY\")\n",
        "    os.system(\"touch AMBER_READY\")\n",
        "  else:\n",
        "    if USE_TEMPLATES and not os.path.isfile(\"HH_READY\"):\n",
        "      print(\"installing hhsuite...\")\n",
        "      os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python='{PYTHON_VERSION}'\")\n",
        "      os.system(\"touch HH_READY\")\n",
        "    if USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
        "      print(\"installing amber...\")\n",
        "      os.system(f\"mamba install -y -c conda-forge openmm=7.7.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
        "      os.system(\"touch AMBER_READY\")\n",
        "  msa_mode = \"single_sequence\"\n",
        "  pair_mode = \"unpaired_paired\"\n",
        "  # decide which a3m to use\n",
        "  if \"mmseqs2\" in msa_mode:\n",
        "    a3m_file = os.path.join(jobname,f\"{jobname}.a3m\")\n",
        "  elif msa_mode == \"custom\":\n",
        "    a3m_file = os.path.join(jobname,f\"{jobname}.custom.a3m\")\n",
        "    if not os.path.isfile(a3m_file):\n",
        "      custom_msa_dict = files.upload()\n",
        "      custom_msa = list(custom_msa_dict.keys())[0]\n",
        "      header = 0\n",
        "      import fileinput\n",
        "      for line in fileinput.FileInput(custom_msa,inplace=1):\n",
        "        if line.startswith(\">\"):\n",
        "          header = header + 1\n",
        "        if not line.rstrip():\n",
        "          continue\n",
        "        if line.startswith(\">\") == False and header == 1:\n",
        "          query_sequence = line.rstrip()\n",
        "        print(line, end='')\n",
        "\n",
        "      os.rename(custom_msa, a3m_file)\n",
        "      queries_path=a3m_file\n",
        "      print(f\"moving {custom_msa} to {a3m_file}\")\n",
        "\n",
        "  else:\n",
        "    a3m_file = os.path.join(jobname,f\"{jobname}.single_sequence.a3m\")\n",
        "    with open(a3m_file, \"w\") as text_file:\n",
        "      text_file.write(\">1\\n%s\" % query_sequence)\n",
        "\n",
        "  model_type = \"alphafold2_ptm\"\n",
        "  num_recycles = \"auto\"\n",
        "  recycle_early_stop_tolerance = \"auto\"\n",
        "  pairing_strategy = \"greedy\"\n",
        "  max_msa = \"auto\"\n",
        "  num_seeds = 1\n",
        "  use_dropout = False\n",
        "  num_recycles = None if num_recycles == \"auto\" else int(num_recycles)\n",
        "  recycle_early_stop_tolerance = None if recycle_early_stop_tolerance == \"auto\" else float(recycle_early_stop_tolerance)\n",
        "  if max_msa == \"auto\": max_msa = None\n",
        "  save_all = False\n",
        "  save_recycles = False\n",
        "  save_to_google_drive = False #@param {type:\"boolean\"}\n",
        "  dpi = 200\n",
        "  if save_to_google_drive:\n",
        "    from pydrive.drive import GoogleDrive\n",
        "    from pydrive.auth import GoogleAuth\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    print(\"You are logged into Google Drive and are good to go!\")\n",
        "  #@title Run Prediction\n",
        "  display_images = False #@param {type:\"boolean\"}\n",
        "\n",
        "  import sys\n",
        "  import warnings\n",
        "  warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "  from Bio import BiopythonDeprecationWarning\n",
        "  warnings.simplefilter(action='ignore', category=BiopythonDeprecationWarning)\n",
        "  from pathlib import Path\n",
        "  from colabfold.download import download_alphafold_params, default_data_dir\n",
        "  from colabfold.utils import setup_logging\n",
        "  from colabfold.batch import get_queries, run, set_model_type\n",
        "  from colabfold.plot import plot_msa_v2\n",
        "\n",
        "  import os\n",
        "  import numpy as np\n",
        "\n",
        "  try:\n",
        "    K80_chk = os.popen('nvidia-smi | grep \"Tesla K80\" | wc -l').read()\n",
        "  except:\n",
        "    K80_chk = \"0\"\n",
        "    pass\n",
        "  if \"1\" in K80_chk:\n",
        "    print(\"WARNING: found GPU Tesla K80: limited to total length < 1000\")\n",
        "    if \"TF_FORCE_UNIFIED_MEMORY\" in os.environ:\n",
        "      del os.environ[\"TF_FORCE_UNIFIED_MEMORY\"]\n",
        "    if \"XLA_PYTHON_CLIENT_MEM_FRACTION\" in os.environ:\n",
        "      del os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]\n",
        "\n",
        "  from colabfold.colabfold import plot_protein\n",
        "  from pathlib import Path\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  # For some reason we need that to get pdbfixer to import\n",
        "  if use_amber and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
        "      sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "  def input_features_callback(input_features):\n",
        "    if display_images:\n",
        "      plot_msa_v2(input_features)\n",
        "      plt.show()\n",
        "      plt.close()\n",
        "\n",
        "  def prediction_callback(protein_obj, length,\n",
        "                          prediction_result, input_features, mode):\n",
        "    model_name, relaxed = mode\n",
        "    if not relaxed:\n",
        "      if display_images:\n",
        "        fig = plot_protein(protein_obj, Ls=length, dpi=150)\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "  result_dir = jobname\n",
        "  log_filename = os.path.join(jobname,\"log.txt\")\n",
        "  if not os.path.isfile(log_filename) or 'logging_setup' not in globals():\n",
        "    setup_logging(Path(log_filename))\n",
        "    logging_setup = True\n",
        "\n",
        "  queries, is_complex = get_queries(queries_path)\n",
        "  model_type = set_model_type(is_complex, model_type)\n",
        "\n",
        "  if \"multimer\" in model_type and max_msa is not None:\n",
        "    use_cluster_profile = False\n",
        "  else:\n",
        "    use_cluster_profile = True\n",
        "\n",
        "  download_alphafold_params(model_type, Path(\".\"))\n",
        "  results = run(\n",
        "      queries=queries,\n",
        "      result_dir=result_dir,\n",
        "      use_templates=use_templates,\n",
        "      custom_template_path=custom_template_path,\n",
        "      num_relax=num_relax,\n",
        "      msa_mode=msa_mode,\n",
        "      model_type=model_type,\n",
        "      num_models=5,\n",
        "      num_recycles=num_recycles,\n",
        "      recycle_early_stop_tolerance=recycle_early_stop_tolerance,\n",
        "      num_seeds=num_seeds,\n",
        "      use_dropout=use_dropout,\n",
        "      model_order=[1,2,3,4,5],\n",
        "      is_complex=is_complex,\n",
        "      data_dir=Path(\".\"),\n",
        "      keep_existing_results=False,\n",
        "      rank_by=\"auto\",\n",
        "      pair_mode=pair_mode,\n",
        "      pairing_strategy=pairing_strategy,\n",
        "      stop_at_score=float(100),\n",
        "      prediction_callback=prediction_callback,\n",
        "      dpi=dpi,\n",
        "      zip_results=False,\n",
        "      save_all=save_all,\n",
        "      max_msa=max_msa,\n",
        "      use_cluster_profile=use_cluster_profile,\n",
        "      input_features_callback=input_features_callback,\n",
        "      save_recycles=save_recycles,\n",
        "  )\n",
        "  pdb_file_path = os.path.join(jobname, \"test.pdb\")\n",
        "  results_zip = f\"{jobname}.result.zip\"\n",
        "  os.system(f\"zip -r {results_zip} {jobname}\")\n",
        "\n",
        "  import locale\n",
        "  def getpreferredencoding(do_setlocale = True):\n",
        "      return \"UTF-8\"\n",
        "  locale.getpreferredencoding = getpreferredencoding\n",
        "  #e.g.path: /content/test_94f6f_6/test_94f6f_6_unrelaxed_rank_001_alphafold2_ptm_model_2_seed_000.pdb\n",
        "  pdb_file_path = os.path.join(jobname, jobname+\"_unrelaxed_rank_001_alphafold2_ptm_model_2_seed_000.pdb\")\n",
        "  # Install necessary packages using pip\n",
        "  !pip install -q matplotlib\n",
        "  !pip install -q numpy\n",
        "  !pip install -q biopython\n",
        "\n",
        "  # Import required libraries\n",
        "  import numpy as np\n",
        "  import matplotlib as mpl\n",
        "  import matplotlib.pyplot as plt\n",
        "  from Bio.SeqUtils import ProtParam\n",
        "  from Bio.PDB import PDBParser\n",
        "  from Bio.PDB import DSSP\n",
        "\n",
        "  #!sudo apt-get install -y dssp\n",
        "  #os.environ['PATH'] += \":/usr/bin/dssp\"\n",
        "  # Step 1: Install packages and prepare variables.\n",
        "\n",
        "  # Define a list of all amino acid residues\n",
        "  all_residues = ['A','B','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','X','Y','Z']\n",
        "\n",
        "  # Define hydrophobicity values for each amino acid residue\n",
        "  hydrophobicity_value = [3.9,25.6,8.3,-0.9,-0.9,29.9,0.0,3.4,22.4,-1.1,24.2,16.3,0.5,9.7,0.5,3.9,0.5,3.9,14.4,32.9,29.5,15.4,-1.1]\n",
        "\n",
        "  # Define hydrophilic residues\n",
        "  hydrophilic_residue = ['Q','N','S','R','D','H','K','Z','E']\n",
        "\n",
        "  # Prompt user to enter a sequence\n",
        "  '''\n",
        "  sequence_2 = input(\"Enter sequence:\")\n",
        "  sequence = np.array(list(sequence_2))\n",
        "  '''\n",
        "  sequence = np.array(list(query_sequence))\n",
        "  # Assign lyticity values to each residue in the peptide sequence\n",
        "  lyticity_assignment = []\n",
        "  for x in sequence:\n",
        "    lyticity_assignment.append(hydrophobicity_value[all_residues.index(x)])\n",
        "\n",
        "  # Create an array of i+4 sums\n",
        "  i_plus_4_sums = []\n",
        "  for i in range(len(sequence)-5):\n",
        "    if sequence[i] not in hydrophilic_residue and sequence[i+4] not in hydrophilic_residue:\n",
        "      i_plus_4_sums.append(lyticity_assignment[i] + lyticity_assignment[i+4])\n",
        "\n",
        "  # Create an array of i+3 sums\n",
        "  i_plus_3_sums = []\n",
        "  for i in range(len(sequence)-4):\n",
        "    if sequence[i] not in hydrophilic_residue and sequence[i+3] not in hydrophilic_residue:\n",
        "      i_plus_3_sums.append(lyticity_assignment[i] + lyticity_assignment[i+3])\n",
        "\n",
        "  # Calculate the total lyticity value by summing i+4 and i+3 sums\n",
        "  total_lyticity = sum(i_plus_4_sums) + sum(i_plus_3_sums)\n",
        "\n",
        "  # Load the protein structure from a PDB file\n",
        "  parser = PDBParser(QUIET=True)\n",
        "\n",
        "  try:\n",
        "    structure = parser.get_structure(\"protein\", pdb_file_path)  # Replace with your PDB file path\n",
        "  except:\n",
        "    try:\n",
        "      pdb_file_path = os.path.join(jobname, jobname+\"_unrelaxed_rank_001_alphafold2_ptm_model_3_seed_000.pdb\")\n",
        "      structure = parser.get_structure(\"protein\", pdb_file_path)  # Replace with your PDB file path\n",
        "    except:\n",
        "      try:\n",
        "        pdb_file_path = os.path.join(jobname, jobname+\"_unrelaxed_rank_001_alphafold2_ptm_model_4_seed_000.pdb\")\n",
        "        structure = parser.get_structure(\"protein\", pdb_file_path)  # Replace with your PDB file path\n",
        "      except:\n",
        "        try:\n",
        "          pdb_file_path = os.path.join(jobname, jobname+\"_unrelaxed_rank_001_alphafold2_ptm_model_5_seed_000.pdb\")\n",
        "          structure = parser.get_structure(\"protein\", pdb_file_path)  # Replace with your PDB file path\n",
        "        except:\n",
        "          pdb_file_path = os.path.join(jobname, jobname+\"_unrelaxed_rank_001_alphafold2_ptm_model_1_seed_000.pdb\")\n",
        "          structure = parser.get_structure(\"protein\", pdb_file_path)  # Replace with your PDB file path\n",
        "  # Define hydrophobicity values for amino acids in a different format\n",
        "  hydrophobicity_values_0 = {\n",
        "      'LLE': 22.4, 'VAL': 14.4, 'LEU': 24.2, 'PHE': 29.9, 'CYS': 8.4,\n",
        "      'MET': 16.3, 'ALA': 3.9, 'GLY': 0.0, 'THR': 3.9, 'SER': 0.5,\n",
        "      'TRP': 32.9, 'TYR': 15.4, 'PRO': 9.7, 'HIS': 3.4, 'GLU': -0.9,\n",
        "      'GLN': 0.5, 'ASP': -0.9, 'ASN': 0.5, 'LYS': -1.1, 'ARG': 3.9\n",
        "  }\n",
        "\n",
        "  # Define hydrophobicity values for individual amino acids\n",
        "  hydrophobicity_values_1 = {\n",
        "      'A': 3.9, 'B': 25.6, 'C': 8.4, 'D': -0.9, 'E': -0.9,\n",
        "      'F': 29.9, 'G': 0.0, 'H': 3.4, 'I': 22.4, 'K': -1.1,\n",
        "      'L': 24.2, 'M': 16.3, 'N': 0.5, 'P': 9.7, 'Q': 0.5,\n",
        "      'R': 3.9, 'S': 0.5, 'T': 3.9, 'V': 14.4, 'W': 32.9,\n",
        "      'X': 29.5, 'Y': 15.4, 'Z': -1.1\n",
        "  }\n",
        "\n",
        "  # Calculate the total hydrophobicity of the input sequence\n",
        "  total_hydrophobicity = sum(hydrophobicity_values_1.get(aa, 0) for aa in query_sequence)\n",
        "\n",
        "  # Initialize variables for the hydrophobic moment vector\n",
        "  hydrophobic_moment_vector = np.zeros(3)\n",
        "\n",
        "  # Iterate through the residues in the protein structure\n",
        "  for model in structure:\n",
        "      for chain in model:\n",
        "          for residue in chain:\n",
        "              amino_acid = residue.get_resname().strip()\n",
        "              # Check if the amino acid is in the hydrophobicity dictionary\n",
        "              if amino_acid in hydrophobicity_values_0:\n",
        "                  hydrophobicity = hydrophobicity_values_0[amino_acid]\n",
        "                  # Get the coordinates of an appropriate atom (e.g., Cα)\n",
        "                  try:\n",
        "                      atom = residue['CA']\n",
        "                      coordinates = atom.get_coord()\n",
        "                      # Calculate the contribution to the hydrophobic moment vector\n",
        "                      hydrophobic_moment_vector += hydrophobicity * coordinates\n",
        "                  except KeyError:\n",
        "                      pass  # Handle missing atom in residue, e.g., Glycine\n",
        "\n",
        "  # Calculate the magnitude of the hydrophobic moment vector\n",
        "  magnitude = np.linalg.norm(hydrophobic_moment_vector)\n",
        "\n",
        "  # Normalize the hydrophobic moment vector\n",
        "  if magnitude > 0:\n",
        "      normalized_hydrophobic_moment = hydrophobic_moment_vector / magnitude\n",
        "  else:\n",
        "      normalized_hydrophobic_moment = np.zeros(3)\n",
        "\n",
        "  # Create a ProteinAnalysis object for the input sequence\n",
        "  protein = ProtParam.ProteinAnalysis(query_sequence)\n",
        "\n",
        "  # Set the pH value for peptide charge calculation\n",
        "  pH_value = 7.0\n",
        "\n",
        "  # Calculate the peptide charge at the specified pH\n",
        "  peptide_charge = protein.charge_at_pH(pH_value)\n",
        "  TL.append(total_lyticity)\n",
        "  TH.append(total_hydrophobicity)\n",
        "  PC.append(peptide_charge)\n",
        "  HM.append(hydrophobic_moment_vector)\n",
        "  NHM.append(normalized_hydrophobic_moment)\n",
        "  return\n",
        "process=0 #process=? Write the start process index here to see the output state during running\n",
        "'''\n",
        "Recursion_Seq(ans[0])\n",
        "Recursion_Seq(ans[1])\n",
        "Recursion_Seq(ans[2])\n",
        "'''\n",
        "#The program use extremely large RAM, you can split the data and run seperately if you don't have enough RAM\n",
        "\n",
        "for i in range(0,len(ans)//2):\n",
        "  process+=1\n",
        "  print(\"Starting Process \"+str(process))\n",
        "  Recursion_Seq(ans[i])\n",
        "  print(\"Process \"+str(process)+\" finish\")\n",
        "\n",
        "\n",
        "'''\n",
        "for i in range(len(ans)//2,len(ans)):\n",
        "  process+=1\n",
        "  print(\"Starting Process \"+str(process))\n",
        "  Recursion_Seq(ans[i])\n",
        "  print(\"Process \"+str(process)+\" finish\")\n",
        "'''\n",
        "\n",
        "\n",
        "#for item in ans:\n",
        "#  Recursion_Seq(item)\n",
        "#  process+=1\n",
        "#  print(process)\n",
        "\n",
        "\n",
        "print('DONE')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Excel Generator\n",
        "fornow=[]\n",
        "aa=[]\n",
        "for i in range(len(ans)//2,len(ans)):\n",
        "  aa.append(ans[i])\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Sequence': aa,\n",
        "    'Lyticity Index': TL,\n",
        "    'Total Hydrophobicity': TH,\n",
        "    'Peptide Charge at pH 7.0': PC,\n",
        "    '3D Hydrophobic Moment Vector': HM,\n",
        "    'Normalized Direction Vector': NHM\n",
        "})\n",
        "\n",
        "results_excel_file = 'sequences_results.xlsx'\n",
        "results_df.to_excel(results_excel_file, index=False)\n",
        "\n",
        "import os\n",
        "\n",
        "# Get the current working directory\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "# Specify the Excel file name\n",
        "excel_file_name = 'sequences_results.xlsx'\n",
        "\n",
        "# Create the full path to the Excel file\n",
        "excel_file_path = os.path.join(current_directory, excel_file_name)\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.isfile(excel_file_path):\n",
        "    print(f\"The Excel file '{excel_file_name}' is located at: {excel_file_path}\")\n",
        "else:\n",
        "    print(f\"The Excel file '{excel_file_name}' was not found in the current directory.\")\n"
      ],
      "metadata": {
        "id": "zAPx8vKotUTR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}